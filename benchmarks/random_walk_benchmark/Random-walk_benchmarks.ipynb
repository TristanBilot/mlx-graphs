{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "from torch_geometric.utils.sparse import index2ptr\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from scipy.sparse import csr_matrix\n",
    "from torch_geometric.nn import Node2Vec\n",
    "import torch\n",
    "from torch_geometric.utils import is_undirected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A unifrom sampling algorithm to create random walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root =\"data/Cora\", name='Cora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using undirected graphs for random walks to keep it simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_undirected(dataset.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the coo matrix into csr and then verify with numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "from torch_geometric.utils import sort_edge_index\n",
    "from torch_geometric.utils.sparse import index2ptr\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, edge_index = dataset.x, dataset.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_cluster in /opt/homebrew/lib/python3.11/site-packages (1.6.3)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.11/site-packages (from torch_cluster) (1.12.0)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in /opt/homebrew/lib/python3.11/site-packages (from scipy->torch_cluster) (1.26.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_cluster.rw import random_walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = maybe_num_nodes(edge_index=edge_index)\n",
    "loader = DataLoader(range(num_nodes), batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Time taken to perform 1000 random walks with Torch_cluster is 0.05887198448181152\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "num_nodes  = maybe_num_nodes(edge_index=edge_index)\n",
    "row, col = sort_edge_index(edge_index=edge_index, num_nodes=num_nodes)\n",
    "row_ptr, col = index2ptr(row, num_nodes), col\n",
    "print(type(col), type(row_ptr))\n",
    "random_walks = torch.ops.torch_cluster.random_walk(row_ptr, col, start, 1000, 1.0, 1.0)\n",
    "print(\"Time taken to perform 1000 random walks with Torch_cluster is\", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch_cluster is insanely fast and has really good performance even on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create own random walk algorithm and measure the time taken on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(row_ptr, col, start, walk_length):\n",
    "    \"\"\"\n",
    "    Computes random walks of length `walk_length` starting from node indices `start` in the\n",
    "    graph given by `(row_ptr, col)` as adjacency matrix in compressed sparse row (CSR) format.\n",
    "\n",
    "    Args:\n",
    "        row_ptr (LongTensor): Row pointers of the adjacency matrix in CSR format.\n",
    "        col (LongTensor): Column indices of the adjacency matrix in CSR format.\n",
    "        start (LongTensor): Indices of starting nodes for random walks.\n",
    "        walk_length (int): Length of random walks.\n",
    "\n",
    "    Returns:\n",
    "        LongTensor: Tensor of shape `(num_starts, walk_length)` containing the nodes indices\n",
    "        of the random walks.\n",
    "    \"\"\"\n",
    "\n",
    "    start = start.flatten()\n",
    "    num_starts = start.shape[0]\n",
    "    out = np.empty((num_starts, walk_length), dtype= col.dtype)\n",
    "    for l in range(walk_length):\n",
    "        if l == 0:\n",
    "            out[:, l] = start\n",
    "        else:\n",
    "            prev = out[:, l - 1]\n",
    "            \n",
    "            prev_nbrs_start = row_ptr[prev]\n",
    "            prev_nbrs_end = row_ptr[prev + 1]\n",
    "            \n",
    "            prev_nbrs = [col[start_idx:end_idx] for start_idx, end_idx in zip(prev_nbrs_start, prev_nbrs_end)]\n",
    "            # Generate random neighbor indices\n",
    "            rand_idx = [np.random.randint(0, len(nbrs)) for nbrs in prev_nbrs]\n",
    "            # Get the corresponding neighbors\n",
    "            next_nbrs = [nbrs[idx] for nbrs, idx in zip(prev_nbrs, rand_idx)]\n",
    "            out[:, l] = next_nbrs\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for random walks using numpy is  1.4987566471099854\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "num_nodes = maybe_num_nodes(edge_index=edge_index)\n",
    "row, col = sort_edge_index(edge_index=edge_index, num_nodes=num_nodes)\n",
    "row_numpy = row.numpy()\n",
    "unique_vals, counts = np.unique(row_numpy, return_counts=True)\n",
    "row_ptr_numpy = np.cumsum(counts)\n",
    "row_ptr_numpy = np.insert(row_ptr_numpy, 0, 0)\n",
    "random_walk(row_ptr_numpy, col.numpy(), start.numpy(), walk_length=1000)\n",
    "print(\"time taken for random walks using numpy is \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running simulations for mlx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlx_graphs.datasets import PlanetoidDataset\n",
    "from mlx_graphs.utils.sorting import sort_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora data ... Done\n"
     ]
    }
   ],
   "source": [
    "cora_dataset = PlanetoidDataset(name='cora', base_dir=\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = cora_dataset.graphs[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_mlx(row_ptr:mx.array, col: mx.array, start:mx.array, walk_length: int):\n",
    "    row_ptr_numpy = np.array(row_ptr, copy = False)\n",
    "    col_numpy = np.array(col, copy= False)\n",
    "    num_starts = start.shape[0]\n",
    "    out = np.zeros((num_starts, walk_length), dtype = col_numpy.dtype)\n",
    "    for l in range(walk_length):\n",
    "        if l == 0:\n",
    "            out[:, l] = start\n",
    "        else:\n",
    "            prev = out[:, l - 1]\n",
    "            prev_nbrs_start = row_ptr_numpy[prev]\n",
    "            prev_nbrs_end = row_ptr_numpy[prev + 1]\n",
    "            \n",
    "            prev_nbrs = [col_numpy[start_idx:end_idx] for start_idx, end_idx in zip(prev_nbrs_start, prev_nbrs_end)]\n",
    "            # Generate random neighbor indices\n",
    "            rand_idx = [np.random.randint(0, len(nbrs)) for nbrs in prev_nbrs]\n",
    "            # Get the corresponding neighbors\n",
    "            next_nbrs = [nbrs[idx] for nbrs, idx in zip(prev_nbrs, rand_idx)]\n",
    "            out[:, l] = next_nbrs\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by mlx and numpy is  1.8042528629302979\n"
     ]
    }
   ],
   "source": [
    "start_time  = time.time()\n",
    "num_nodes = cora_dataset.graphs[0].num_nodes\n",
    "sorted_edge_index = sort_edge_index(edge_index=edge_index)\n",
    "row_mlx = sorted_edge_index[0][0]\n",
    "col_mlx = sorted_edge_index[0][1]\n",
    "unique_vals, counts_mlx = np.unique(np.array(row_mlx, copy = False), return_counts=True)\n",
    "cum_sum_mlx = counts_mlx.cumsum()\n",
    "row_ptr_mlx = mx.concatenate([mx.array([0]),mx.array(cum_sum_mlx)])\n",
    "random_walk_mlx(row_ptr_mlx, col_mlx, start=start, walk_length=1000)\n",
    "print(\"Time taken by mlx and numpy is \", time.time()-start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
