{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "from torch_geometric.utils.sparse import index2ptr\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from scipy.sparse import csr_matrix\n",
    "from torch_geometric.nn import Node2Vec\n",
    "import torch\n",
    "from torch_geometric.utils import is_undirected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root =\"data/Cora\", name='Cora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the coo matrix into csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "from torch_geometric.utils import sort_edge_index\n",
    "from torch_geometric.utils.sparse import index2ptr\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, edge_index = dataset.x, dataset.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_cluster in /opt/homebrew/lib/python3.11/site-packages (1.6.3)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.11/site-packages (from torch_cluster) (1.12.0)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in /opt/homebrew/lib/python3.11/site-packages (from scipy->torch_cluster) (1.26.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_cluster.rw import random_walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = maybe_num_nodes(edge_index=edge_index)\n",
    "loader = DataLoader(range(num_nodes), batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Benchmarking torch cluster for generating 1000 random walks ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Time taken to perform 1000 random walks with Torch_cluster is 0.04140591621398926\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "num_nodes  = maybe_num_nodes(edge_index=edge_index)\n",
    "row, col = sort_edge_index(edge_index=edge_index, num_nodes=num_nodes)\n",
    "row_ptr, col = index2ptr(row, num_nodes), col\n",
    "print(type(col), type(row_ptr))\n",
    "random_walks = torch.ops.torch_cluster.random_walk(row_ptr, col, start, 1000, 1.0, 1.0)\n",
    "print(\"Time taken to perform 1000 random walks with Torch_cluster is\", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with CPU, torch cluster's effecient implementation can generate 1000 random walks pretty quickly. The reason behind `torch_cluster` being so effecient lies in its optimized parallel processing algorithms written in c++\n",
    "~~~cpp\n",
    "auto rand = torch::rand({numel, walk_length});\n",
    "  auto rand_data = rand.data_ptr<float>();\n",
    "\n",
    "  int64_t grain_size = at::internal::GRAIN_SIZE / walk_length;\n",
    "  at::parallel_for(0, numel, grain_size, [&](int64_t begin, int64_t end) {\n",
    "    for (auto n = begin; n < end; n++) {\n",
    "      int64_t n_cur = start[n], e_cur, row_start, row_end, idx;\n",
    "\n",
    "      n_out[n * (walk_length + 1)] = n_cur;\n",
    "\n",
    "      for (auto l = 0; l < walk_length; l++) {\n",
    "        row_start = rowptr[n_cur], row_end = rowptr[n_cur + 1];\n",
    "        if (row_end - row_start == 0) {\n",
    "          e_cur = -1;\n",
    "        } else {\n",
    "          idx = int64_t(rand_data[n * walk_length + l] * (row_end - row_start));\n",
    "          e_cur = row_start + idx;\n",
    "          n_cur = col[e_cur];\n",
    "        }\n",
    "        n_out[n * (walk_length + 1) + (l + 1)] = n_cur;\n",
    "        e_out[n * walk_length + l] = e_cur;\n",
    "      }\n",
    "    }\n",
    "  });\n",
    "~~~ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code generates the threads which are defined in `ATen` library by pytorch for its C++ api, which then iterate through each of the nodes neighbors and generate a random walk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmarking random walks using numpy ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create own random walk algorithm and measure the time taken on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_numpy_optimized(rowptr, col, start, walk_length, rand_data):\n",
    "    num_walks = len(start)\n",
    "    num_nodes = len(rowptr) - 1\n",
    "    \n",
    "    n_out = np.zeros((num_walks, walk_length + 1), dtype=np.int64) \n",
    "    e_out = np.zeros((num_walks, walk_length), dtype=np.int64)\n",
    "    \n",
    "    n_out[:, 0] = start\n",
    "    \n",
    "    for l in range(walk_length):\n",
    "        n_cur = n_out[:, l]\n",
    "        row_start = rowptr[n_cur]\n",
    "        row_end = rowptr[n_cur + 1]\n",
    "        \n",
    "        mask = (row_end - row_start) > 0\n",
    "        num_neighbors = row_end - row_start\n",
    "        \n",
    "        rand_idx = (rand_data[l::walk_length] * num_neighbors).astype(np.int64)\n",
    "        e_cur = row_start + rand_idx\n",
    "        n_cur = col[e_cur]\n",
    "        \n",
    "        n_cur[~mask] = n_out[~mask, l]\n",
    "        e_cur[~mask] = -1\n",
    "        \n",
    "        n_out[:, l + 1] = n_cur\n",
    "        e_out[:, l] = e_cur\n",
    "    \n",
    "    return n_out, e_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for random walks using numpy is  0.07817220687866211\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "num_nodes = maybe_num_nodes(edge_index=edge_index)\n",
    "row, col = sort_edge_index(edge_index=edge_index, num_nodes=num_nodes)\n",
    "row_numpy = row.numpy()\n",
    "unique_vals, counts = np.unique(row_numpy, return_counts=True)\n",
    "row_ptr_numpy = np.cumsum(counts)\n",
    "row_ptr_numpy = np.insert(row_ptr_numpy, 0, 0)\n",
    "rand_data = np.random.rand(1000, 1000).astype(np.float32).flatten()\n",
    "random_walk_numpy_optimized(row_ptr_numpy, col.numpy(), start.numpy(), walk_length=1000, rand_data=rand_data)\n",
    "print(\"time taken for random walks using numpy is \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy's effeciency is quite slow as compared to that of torc_cluster by 100x. Although the speed can be improved by using a JIT compiler like Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking simulations for mlx ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we achieve similar results in MLX?. Although torch_cluster seems to utilize low level parallel optimizations to speed up computation. It still relies on CPU and nvidia GPU for faster processing. Since MLX can interface with GPU's directly, we should be able to speed up the process and achieve comparable performance with mlx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlx_graphs.datasets import PlanetoidDataset\n",
    "from mlx_graphs.utils.sorting import sort_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora data ... Done\n"
     ]
    }
   ],
   "source": [
    "cora_dataset = PlanetoidDataset(name='cora', base_dir=\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = cora_dataset.graphs[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@mx.compile\n",
    "def random_walk_mlx(row_ptr:mx.array, col: mx.array, start:mx.array, walk_length: int, rand_data):\n",
    "    num_walks = len(start)\n",
    "    num_nodes = row_ptr.shape[0]-1\n",
    "    n_out = mx.zeros((num_walks, walk_length + 1), dtype=col.dtype)\n",
    "    e_out = mx.zeros((num_walks, walk_length), dtype=col.dtype)\n",
    "\n",
    "    n_out[:, 0] = start\n",
    "\n",
    "    for l in range(walk_length):\n",
    "        n_cur = n_out[:, l]\n",
    "\n",
    "        row_start = row_ptr[n_cur]\n",
    "        row_end = row_ptr[n_cur + 1]\n",
    "\n",
    "        mask = (row_end - row_start) > 0\n",
    "        num_neighbors = row_end - row_start\n",
    "\n",
    "        rand_idx = (rand_data[l::walk_length] * num_neighbors)\n",
    "        rand_idx = rand_idx.astype(mx.int64)\n",
    "        e_cur = row_start + rand_idx\n",
    "        n_cur = col[e_cur]\n",
    "        n_cur = mx.where(~mask, n_out[:, l], n_cur)\n",
    "        e_cur = mx.where(~mask, -1, e_cur)\n",
    "\n",
    "        n_out[:, l + 1] = n_cur\n",
    "        e_out[:, l] = e_cur\n",
    "\n",
    "    return n_out, e_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by mlx and numpy is  0.03845572471618652\n"
     ]
    }
   ],
   "source": [
    "start_time  = time.time()\n",
    "num_nodes = cora_dataset.graphs[0].num_nodes\n",
    "sorted_edge_index = sort_edge_index(edge_index=edge_index)\n",
    "row_mlx = sorted_edge_index[0][0]\n",
    "col_mlx = sorted_edge_index[0][1]\n",
    "unique_vals, counts_mlx = np.unique(np.array(row_mlx, copy = False), return_counts=True)\n",
    "cum_sum_mlx = counts_mlx.cumsum()\n",
    "row_ptr_mlx = mx.concatenate([mx.array([0]),mx.array(cum_sum_mlx)])\n",
    "rand_data = mx.random.uniform(shape = [1000, 1000]).flatten()\n",
    "random_walk_mlx(row_ptr_mlx, col_mlx, start=mx.array(start.numpy()), walk_length=1000, rand_data=rand_data)\n",
    "print(\"Time taken by mlx and numpy is \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `mx.compile`, we can speed up the computation y almost 3x. ALthough first iteration of compilation will be slow as mlx will build the compiled graph, optimize it and then generate compiled code. After the graph is build, computation is significantly faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
